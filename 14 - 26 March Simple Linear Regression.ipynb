{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8f5692-a739-4716-831d-88a8c6e80b14",
   "metadata": {},
   "source": [
    "## Simple Linear Regression Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae9fd8c-99d6-4a08-a409-68259aadefbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\\nexample of each.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138f0b8a-3c6c-41f3-9334-3dfddea8b9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simple linear regression and multiple linear regression are both statistical techniques used to model the relationship between a dependent variable and one or more independent variables.\\nThe key difference lies in the number of independent variables involved.\\n\\nSimple Linear Regression:\\n\\nDefinition: Simple linear regression involves only one independent variable to predict the dependent variable.\\n\\n\\n\\nMultiple Linear Regression:\\n\\nDefinition: Multiple linear regression involves more than one independent variable to predict the dependent variable.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''Simple linear regression and multiple linear regression are both statistical techniques used to model the relationship between a dependent variable and one or more independent variables.\n",
    "The key difference lies in the number of independent variables involved.\n",
    "\n",
    "Simple Linear Regression:\n",
    "\n",
    "Definition: Simple linear regression involves only one independent variable to predict the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "Multiple Linear Regression:\n",
    "\n",
    "Definition: Multiple linear regression involves more than one independent variable to predict the dependent variable.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ffaf8a-fadb-43be-bfa6-924c6caea383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate some random data for the example\n",
    "np.random.seed(42)\n",
    "X_simple = 2 * np.random.rand(100, 1)\n",
    "y_simple = 4 + 3 * X_simple + np.random.randn(100, 1)\n",
    "\n",
    "# Create a simple linear regression model\n",
    "simple_reg_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "simple_reg_model.fit(X_simple, y_simple)\n",
    "\n",
    "# Make predictions\n",
    "X_new_simple = np.array([[0], [2]])\n",
    "y_pred_simple = simple_reg_model.predict(X_new_simple)\n",
    "\n",
    "# Plot the data and regression line\n",
    "plt.scatter(X_simple, y_simple)\n",
    "plt.plot(X_new_simple, y_pred_simple, \"r-\", label=\"Linear Regression\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Simple Linear Regression Example\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b4823d-d3d3-4b27-98ab-870709075e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients (b0, b1, b2): 4.109317964436262 [2.86963923 2.10119826]\n",
      "Predictions: [ 4.10931796 16.15219122]\n"
     ]
    }
   ],
   "source": [
    "# Generate some random data for the example\n",
    "X_multiple = 2 * np.random.rand(100, 2)\n",
    "y_multiple = 4 + 3 * X_multiple[:, 0] + 2 * X_multiple[:, 1] + np.random.randn(100)\n",
    "\n",
    "# Create a multiple linear regression model\n",
    "multiple_reg_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "multiple_reg_model.fit(X_multiple, y_multiple)\n",
    "\n",
    "# Make predictions\n",
    "X_new_multiple = np.array([[0, 0], [2, 3]])\n",
    "y_pred_multiple = multiple_reg_model.predict(X_new_multiple)\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Coefficients (b0, b1, b2):\", multiple_reg_model.intercept_, multiple_reg_model.coef_)\n",
    "\n",
    "# The coefficients represent the intercept (b0) and slopes (b1, b2)\n",
    "\n",
    "# Note: Visualization is challenging in multiple dimensions, but you can analyze the coefficients.\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", y_pred_multiple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44820d7d-3453-4bae-bedd-25b0f4d1bee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\\na given dataset?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f3de44-0aad-4da7-9a94-9411a431b32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Linear regression makes several assumptions about the underlying data. It's important to check these assumptions to ensure the reliability of the regression model. Here are the key assumptions of linear regression:\\n\\n1. Linearity:\\nAssumption: The relationship between the independent and dependent variables is linear.\\n\\nCheck: Examine scatter plots of each independent variable against the dependent variable. A linear pattern in these plots suggests linearity.\\n\\n2. Independence:\\nAssumption: The residuals (the differences between observed and predicted values) should be independent.\\n\\nCheck: Look for patterns or trends in the residuals. If there is a systematic pattern, it suggests that there might be a violation of independence.\\n\\n3. Homoscedasticity:\\nAssumption: The variance of the residuals should be constant across all levels of the independent variable(s).\\n\\nCheck: Plot the residuals against the predicted values. If the spread of residuals is consistent across the range of predictions, homoscedasticity is likely satisfied. If the spread fans out or contracts, there may be an issue.\\n\\n4. Normality of Residuals:\\nAssumption: The residuals should be normally distributed.\\n\\nCheck: Create a histogram or a Q-Q plot of the residuals. If the distribution is approximately normal, this assumption is likely met. Statistical tests, like the Shapiro-Wilk test, can also be used for a formal assessment.\\n\\n5. No Perfect Multicollinearity:\\nAssumption: There should be no perfect linear relationship between independent variables.\\n\\nCheck: Calculate the variance inflation factor (VIF) for each independent variable. High VIF values (typically above 10) may indicate multicollinearity.\\n\\n6. No Autocorrelation:\\nAssumption: The residuals should not display autocorrelation; i.e., they should be independent of each other.\\n\\nCheck: Use residual plots or autocorrelation functions (ACF) to detect patterns in residuals over time or across observations. No clear patterns indicate no autocorrelation.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Linear regression makes several assumptions about the underlying data. It's important to check these assumptions to ensure the reliability of the regression model. Here are the key assumptions of linear regression:\n",
    "\n",
    "1. Linearity:\n",
    "Assumption: The relationship between the independent and dependent variables is linear.\n",
    "\n",
    "Check: Examine scatter plots of each independent variable against the dependent variable. A linear pattern in these plots suggests linearity.\n",
    "\n",
    "2. Independence:\n",
    "Assumption: The residuals (the differences between observed and predicted values) should be independent.\n",
    "\n",
    "Check: Look for patterns or trends in the residuals. If there is a systematic pattern, it suggests that there might be a violation of independence.\n",
    "\n",
    "3. Homoscedasticity:\n",
    "Assumption: The variance of the residuals should be constant across all levels of the independent variable(s).\n",
    "\n",
    "Check: Plot the residuals against the predicted values. If the spread of residuals is consistent across the range of predictions, homoscedasticity is likely satisfied. If the spread fans out or contracts, there may be an issue.\n",
    "\n",
    "4. Normality of Residuals:\n",
    "Assumption: The residuals should be normally distributed.\n",
    "\n",
    "Check: Create a histogram or a Q-Q plot of the residuals. If the distribution is approximately normal, this assumption is likely met. Statistical tests, like the Shapiro-Wilk test, can also be used for a formal assessment.\n",
    "\n",
    "5. No Perfect Multicollinearity:\n",
    "Assumption: There should be no perfect linear relationship between independent variables.\n",
    "\n",
    "Check: Calculate the variance inflation factor (VIF) for each independent variable. High VIF values (typically above 10) may indicate multicollinearity.\n",
    "\n",
    "6. No Autocorrelation:\n",
    "Assumption: The residuals should not display autocorrelation; i.e., they should be independent of each other.\n",
    "\n",
    "Check: Use residual plots or autocorrelation functions (ACF) to detect patterns in residuals over time or across observations. No clear patterns indicate no autocorrelation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa62f019-f0c9-44eb-a1ed-3489c03a5d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\\na real-world scenario.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4c9a07-d16b-43c2-8283-66603ecc49a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In a linear regression model, the slope and intercept have specific interpretations that help understand the relationship between the independent and dependent variables.\\n\\n1. Intercept (b0):\\nInterpretation: The intercept represents the predicted value of the dependent variable when all independent variables are set to zero.\\nExample: If a linear regression model predicts house prices based on the size of the house, the intercept would be the estimated house price when the size is zero. However, in many practical scenarios, the interpretation of the intercept without context might not be meaningful.\\n\\n2. Slope (b1):\\nInterpretation: The slope represents the change in the dependent variable for a one-unit change in the corresponding independent variable, assuming all other variables are held constant.\\nExample: In a model predicting exam scores based on hours of study, a slope of 2 means that, on average, each additional hour of study is associated with a 2-point increase in the predicted exam score, assuming other factors remain constant.\\n\\nReal-world Example:\\nLet's consider a real-world scenario where we want to predict the salary of an employee based on the number of years of experience.\\n\\nLinear Regression Model:\\n    \\nSalary=b0+b1*Years of Experience\\n\\nIntercept (b0): $30,000 (This is the predicted salary when the years of experience are zero, which might not make practical sense in this context.)\\n\\nSlope (b1): $5,000 (This means that, on average, each additional year of experience is associated with a $5,000 increase in salary, assuming other factors remain constant.)\\n\\nInterpretation:\\nIf an employee has zero years of experience, the model predicts a salary of $30,000.\\nFor each additional year of experience, the predicted salary increases by $5,000, assuming other factors like education level, job role, etc., remain constant.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''In a linear regression model, the slope and intercept have specific interpretations that help understand the relationship between the independent and dependent variables.\n",
    "\n",
    "1. Intercept (b0):\n",
    "Interpretation: The intercept represents the predicted value of the dependent variable when all independent variables are set to zero.\n",
    "Example: If a linear regression model predicts house prices based on the size of the house, the intercept would be the estimated house price when the size is zero. However, in many practical scenarios, the interpretation of the intercept without context might not be meaningful.\n",
    "\n",
    "2. Slope (b1):\n",
    "Interpretation: The slope represents the change in the dependent variable for a one-unit change in the corresponding independent variable, assuming all other variables are held constant.\n",
    "Example: In a model predicting exam scores based on hours of study, a slope of 2 means that, on average, each additional hour of study is associated with a 2-point increase in the predicted exam score, assuming other factors remain constant.\n",
    "\n",
    "Real-world Example:\n",
    "Let's consider a real-world scenario where we want to predict the salary of an employee based on the number of years of experience.\n",
    "\n",
    "Linear Regression Model:\n",
    "    \n",
    "Salary=b0+b1*Years of Experience\n",
    "\n",
    "Intercept (b0): $30,000 (This is the predicted salary when the years of experience are zero, which might not make practical sense in this context.)\n",
    "\n",
    "Slope (b1): $5,000 (This means that, on average, each additional year of experience is associated with a $5,000 increase in salary, assuming other factors remain constant.)\n",
    "\n",
    "Interpretation:\n",
    "If an employee has zero years of experience, the model predicts a salary of $30,000.\n",
    "For each additional year of experience, the predicted salary increases by $5,000, assuming other factors like education level, job role, etc., remain constant.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e95b5c-4ba0-4d4e-a11a-cd21eead5f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q4. Explain the concept of gradient descent. How is it used in machine learning?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q4. Explain the concept of gradient descent. How is it used in machine learning?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce1cdd7-4a93-405a-a471-a5f327ea13e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGradient Descent is an optimization algorithm used to minimize the cost function in machine learning models. The primary goal is to iteratively adjust the model parameters to reach the minimum of the cost function, which represents the difference between the predicted values and the actual values in the training data.\\n\\nHere's a step-by-step explanation of how gradient descent works:\\n\\nInitialize Parameters:\\n\\nStart with initial values for the model parameters (weights and biases).\\nCompute the Cost Function:\\n\\nUse the current parameter values to compute the cost function, which measures the difference between the predicted values and the actual values in the training data.\\nCompute the Gradient:\\n\\nCalculate the gradient of the cost function with respect to each parameter. The gradient points in the direction of the steepest increase of the cost function.\\nUpdate Parameters:\\n\\nAdjust the parameters in the opposite direction of the gradient. This step involves multiplying the gradient by a learning rate and subtracting it from the current parameter values.\\nRepeat:\\n\\nRepeat steps 2-4 until the cost function converges to a minimum or a predefined number of iterations is reached.\\nMathematically:\\nNew Parameter\\n=\\nOld Parameter\\n−\\nLearning Rate\\n×\\nGradient of the Cost Function\\nNew Parameter=Old Parameter−Learning Rate×Gradient of the Cost Function\\n\\nKey Components:\\n\\nLearning Rate: Determines the size of the steps taken during parameter updates. It is a hyperparameter that needs to be carefully chosen; too small a learning rate may lead to slow convergence, and too large a learning rate may cause overshooting.\\n\\nGradient: The partial derivatives of the cost function with respect to each parameter. It indicates the direction and rate of the steepest ascent.\\n\\nUse in Machine Learning:\\n\\nGradient Descent is a fundamental optimization algorithm widely used in various machine learning models, especially for training linear regression, logistic regression, and neural networks. It helps these models learn optimal parameter values by minimizing the difference between predicted and actual outcomes.\\n\\nFor example, in training a linear regression model, gradient descent adjusts the weights and bias to minimize the mean squared error between predicted and actual values. In the context of neural networks, it's crucial for updating the weights during backpropagation to minimize the overall loss function.\\n\\nThe efficiency and convergence of gradient descent make it a go-to optimization algorithm for training models in machine learning. Different variants of gradient descent, such as Stochastic Gradient Descent (SGD) and Mini-batch Gradient Descent, adapt the algorithm to handle large datasets and speed up convergence.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning models. The primary goal is to iteratively adjust the model parameters to reach the minimum of the cost function, which represents the difference between the predicted values and the actual values in the training data.\n",
    "\n",
    "Here's a step-by-step explanation of how gradient descent works:\n",
    "\n",
    "Initialize Parameters:\n",
    "\n",
    "Start with initial values for the model parameters (weights and biases).\n",
    "Compute the Cost Function:\n",
    "\n",
    "Use the current parameter values to compute the cost function, which measures the difference between the predicted values and the actual values in the training data.\n",
    "Compute the Gradient:\n",
    "\n",
    "Calculate the gradient of the cost function with respect to each parameter. The gradient points in the direction of the steepest increase of the cost function.\n",
    "Update Parameters:\n",
    "\n",
    "Adjust the parameters in the opposite direction of the gradient. This step involves multiplying the gradient by a learning rate and subtracting it from the current parameter values.\n",
    "Repeat:\n",
    "\n",
    "Repeat steps 2-4 until the cost function converges to a minimum or a predefined number of iterations is reached.\n",
    "Mathematically:\n",
    "New Parameter\n",
    "=\n",
    "Old Parameter\n",
    "−\n",
    "Learning Rate\n",
    "×\n",
    "Gradient of the Cost Function\n",
    "New Parameter=Old Parameter−Learning Rate×Gradient of the Cost Function\n",
    "\n",
    "Key Components:\n",
    "\n",
    "Learning Rate: Determines the size of the steps taken during parameter updates. It is a hyperparameter that needs to be carefully chosen; too small a learning rate may lead to slow convergence, and too large a learning rate may cause overshooting.\n",
    "\n",
    "Gradient: The partial derivatives of the cost function with respect to each parameter. It indicates the direction and rate of the steepest ascent.\n",
    "\n",
    "Use in Machine Learning:\n",
    "\n",
    "Gradient Descent is a fundamental optimization algorithm widely used in various machine learning models, especially for training linear regression, logistic regression, and neural networks. It helps these models learn optimal parameter values by minimizing the difference between predicted and actual outcomes.\n",
    "\n",
    "For example, in training a linear regression model, gradient descent adjusts the weights and bias to minimize the mean squared error between predicted and actual values. In the context of neural networks, it's crucial for updating the weights during backpropagation to minimize the overall loss function.\n",
    "\n",
    "The efficiency and convergence of gradient descent make it a go-to optimization algorithm for training models in machine learning. Different variants of gradient descent, such as Stochastic Gradient Descent (SGD) and Mini-batch Gradient Descent, adapt the algorithm to handle large datasets and speed up convergence.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4e88ac-1981-4e20-b0a7-55d9ac321a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa73e6a9-8b41-4efe-8d7b-1d5ddc434622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nMultiple Linear Regression Model:\\n\\nMultiple Linear Regression is an extension of simple linear regression that allows us to model the relationship between a dependent variable and two or more independent variables. In simple terms, it considers the influence of multiple factors on the outcome.\\n\\nKey Characteristics:\\n\\nMultiple Independent Variables:\\n\\nWhile simple linear regression involves only one independent variable, multiple linear regression includes two or more independent variables. This enables the model to capture the combined effect of different factors on the dependent variable.\\nIncreased Complexity:\\n\\nWith multiple linear regression, the model can handle more complex relationships by considering the simultaneous impact of various independent variables. This is particularly useful in real-world scenarios where outcomes are often influenced by multiple factors.\\nInterpretation of Coefficients:\\n\\nIn simple linear regression, there's a single slope coefficient representing the change in the dependent variable for a one-unit change in the independent variable. In multiple linear regression, each independent variable has its own coefficient, representing its unique contribution to the dependent variable while holding other variables constant.\\nFlexibility and Real-world Applicability:\\n\\nMultiple linear regression is suitable for situations where the outcome is influenced by multiple factors. For example, predicting a house price might involve considering not only the size of the house (simple linear regression) but also the number of bedrooms, the neighborhood's crime rate, and other relevant factors (multiple linear regression).\\nModel Complexity:\\n\\nSimple linear regression models a linear relationship between two variables using a straight line. Multiple linear regression allows for modeling a more intricate relationship involving multiple variables. This added complexity can often result in a more accurate representation of real-world phenomena.\\nDifferences from Simple Linear Regression:\\n\\nNumber of Independent Variables:\\n\\nSimple linear regression involves only one independent variable, while multiple linear regression deals with two or more independent variables.\\nScope and Flexibility:\\n\\nSimple linear regression is limited to scenarios where there's a single predictor for the outcome. Multiple linear regression provides more flexibility to account for various influencing factors.\\nInterpretability:\\n\\nCoefficients in simple linear regression are straightforward to interpret, representing the slope of the relationship. In multiple linear regression, interpretation involves understanding how each independent variable contributes to the dependent variable in the presence of other variables.\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Multiple Linear Regression Model:\n",
    "\n",
    "Multiple Linear Regression is an extension of simple linear regression that allows us to model the relationship between a dependent variable and two or more independent variables. In simple terms, it considers the influence of multiple factors on the outcome.\n",
    "\n",
    "Key Characteristics:\n",
    "\n",
    "Multiple Independent Variables:\n",
    "\n",
    "While simple linear regression involves only one independent variable, multiple linear regression includes two or more independent variables. This enables the model to capture the combined effect of different factors on the dependent variable.\n",
    "Increased Complexity:\n",
    "\n",
    "With multiple linear regression, the model can handle more complex relationships by considering the simultaneous impact of various independent variables. This is particularly useful in real-world scenarios where outcomes are often influenced by multiple factors.\n",
    "Interpretation of Coefficients:\n",
    "\n",
    "In simple linear regression, there's a single slope coefficient representing the change in the dependent variable for a one-unit change in the independent variable. In multiple linear regression, each independent variable has its own coefficient, representing its unique contribution to the dependent variable while holding other variables constant.\n",
    "Flexibility and Real-world Applicability:\n",
    "\n",
    "Multiple linear regression is suitable for situations where the outcome is influenced by multiple factors. For example, predicting a house price might involve considering not only the size of the house (simple linear regression) but also the number of bedrooms, the neighborhood's crime rate, and other relevant factors (multiple linear regression).\n",
    "Model Complexity:\n",
    "\n",
    "Simple linear regression models a linear relationship between two variables using a straight line. Multiple linear regression allows for modeling a more intricate relationship involving multiple variables. This added complexity can often result in a more accurate representation of real-world phenomena.\n",
    "Differences from Simple Linear Regression:\n",
    "\n",
    "Number of Independent Variables:\n",
    "\n",
    "Simple linear regression involves only one independent variable, while multiple linear regression deals with two or more independent variables.\n",
    "Scope and Flexibility:\n",
    "\n",
    "Simple linear regression is limited to scenarios where there's a single predictor for the outcome. Multiple linear regression provides more flexibility to account for various influencing factors.\n",
    "Interpretability:\n",
    "\n",
    "Coefficients in simple linear regression are straightforward to interpret, representing the slope of the relationship. In multiple linear regression, interpretation involves understanding how each independent variable contributes to the dependent variable in the presence of other variables.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b50ae3b-a4ce-47f1-87fd-e82748ec86e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\\naddress this issue?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd8085ee-1ab3-42f1-93f2-4803d856b1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMulticollinearity in Multiple Linear Regression:\\n\\nMulticollinearity is a phenomenon in multiple linear regression where two or more independent variables in the model are highly correlated with each other. This high correlation can cause issues in the estimation of individual coefficients and may affect the overall interpretation of the model.\\n\\nKey Points:\\n\\nCorrelation Among Independent Variables:\\n\\nMulticollinearity arises when there is a strong correlation between at least two independent variables.\\nImpact on Coefficients:\\n\\nHigh multicollinearity can lead to unstable and imprecise estimates of the regression coefficients. It becomes challenging to identify the independent contribution of each variable to the dependent variable.\\nIncreased Standard Errors:\\n\\nStandard errors of the coefficients may increase, making it difficult to determine the statistical significance of individual variables.\\nInflated Variance Inflation Factor (VIF):\\n\\nVIF is a measure to quantify the extent of multicollinearity. A high VIF (typically above 10) indicates a problematic level of multicollinearity for a particular variable.\\nDetection of Multicollinearity:\\n\\nCorrelation Matrix:\\n\\nExamine the correlation matrix between independent variables. High absolute values of correlation coefficients (close to 1) suggest potential multicollinearity.\\nVariance Inflation Factor (VIF):\\n\\nCalculate the VIF for each independent variable. A high VIF indicates that the variable is highly correlated with other variables in the model.\\nTolerance:\\n\\nTolerance is another measure related to VIF. Low tolerance values (close to 0) indicate multicollinearity.\\nAddressing Multicollinearity:\\n\\nVariable Removal:\\n\\nIf multicollinearity is detected, consider removing one of the correlated variables. Prioritize keeping variables that are theoretically important or have practical significance.\\nData Transformation:\\n\\nTransform variables to reduce multicollinearity. For example, you can use dimensionality reduction techniques like Principal Component Analysis (PCA) or ridge regression.\\nCombine Variables:\\n\\nIf possible, combine highly correlated variables into a single variable that captures the shared information. This can help mitigate multicollinearity.\\nRegularization Techniques:\\n\\nTechniques like ridge regression introduce a penalty term that helps stabilize the estimation of coefficients in the presence of multicollinearity.\\nIncrease Sample Size:\\n\\nSometimes multicollinearity is an issue due to a small sample size. Increasing the sample size may help alleviate the problem.\\nUse Partial Correlations:\\n\\nAnalyze partial correlations, which measure the correlation between two variables while controlling for the effects of other variables. This can help identify the unique contribution of each variable.\\nAddressing multicollinearity is crucial to ensure the reliability of multiple linear regression results. The choice of the specific method to address multicollinearity depends on the context of the problem and the nature of the data.\\n\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Multicollinearity in Multiple Linear Regression:\n",
    "\n",
    "Multicollinearity is a phenomenon in multiple linear regression where two or more independent variables in the model are highly correlated with each other. This high correlation can cause issues in the estimation of individual coefficients and may affect the overall interpretation of the model.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Correlation Among Independent Variables:\n",
    "\n",
    "Multicollinearity arises when there is a strong correlation between at least two independent variables.\n",
    "Impact on Coefficients:\n",
    "\n",
    "High multicollinearity can lead to unstable and imprecise estimates of the regression coefficients. It becomes challenging to identify the independent contribution of each variable to the dependent variable.\n",
    "Increased Standard Errors:\n",
    "\n",
    "Standard errors of the coefficients may increase, making it difficult to determine the statistical significance of individual variables.\n",
    "Inflated Variance Inflation Factor (VIF):\n",
    "\n",
    "VIF is a measure to quantify the extent of multicollinearity. A high VIF (typically above 10) indicates a problematic level of multicollinearity for a particular variable.\n",
    "Detection of Multicollinearity:\n",
    "\n",
    "Correlation Matrix:\n",
    "\n",
    "Examine the correlation matrix between independent variables. High absolute values of correlation coefficients (close to 1) suggest potential multicollinearity.\n",
    "Variance Inflation Factor (VIF):\n",
    "\n",
    "Calculate the VIF for each independent variable. A high VIF indicates that the variable is highly correlated with other variables in the model.\n",
    "Tolerance:\n",
    "\n",
    "Tolerance is another measure related to VIF. Low tolerance values (close to 0) indicate multicollinearity.\n",
    "Addressing Multicollinearity:\n",
    "\n",
    "Variable Removal:\n",
    "\n",
    "If multicollinearity is detected, consider removing one of the correlated variables. Prioritize keeping variables that are theoretically important or have practical significance.\n",
    "Data Transformation:\n",
    "\n",
    "Transform variables to reduce multicollinearity. For example, you can use dimensionality reduction techniques like Principal Component Analysis (PCA) or ridge regression.\n",
    "Combine Variables:\n",
    "\n",
    "If possible, combine highly correlated variables into a single variable that captures the shared information. This can help mitigate multicollinearity.\n",
    "Regularization Techniques:\n",
    "\n",
    "Techniques like ridge regression introduce a penalty term that helps stabilize the estimation of coefficients in the presence of multicollinearity.\n",
    "Increase Sample Size:\n",
    "\n",
    "Sometimes multicollinearity is an issue due to a small sample size. Increasing the sample size may help alleviate the problem.\n",
    "Use Partial Correlations:\n",
    "\n",
    "Analyze partial correlations, which measure the correlation between two variables while controlling for the effects of other variables. This can help identify the unique contribution of each variable.\n",
    "Addressing multicollinearity is crucial to ensure the reliability of multiple linear regression results. The choice of the specific method to address multicollinearity depends on the context of the problem and the nature of the data.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee0201d-5796-4ccf-9156-a694e28d2bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q7. Describe the polynomial regression model. How is it different from linear regression?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q7. Describe the polynomial regression model. How is it different from linear regression?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc1b7ff-824d-453b-9ed2-c4498a909285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Polynomial Regression:\\n\\nHandles Non-Linear Relationships: It's a regression technique that models non-linear relationships between variables. Instead of fitting a straight line, it fits a curve to the data, represented by a polynomial equation.\\nFlexible Patterns: It can capture various patterns, including U-shapes, inverted U-shapes, and multiple peaks and valleys, making it more adaptable than linear regression for complex relationships.\\nDegree of Polynomial: The model's flexibility is determined by the degree of the polynomial used (e.g., quadratic, cubic, quartic). Higher degrees allow for more complex curves but also increase the risk of overfitting.\\nKey Differences from Linear Regression:\\n\\nRelationship Shape:\\n\\nLinear regression assumes a straight-line relationship between variables.\\nPolynomial regression allows for non-linear, curved relationships.\\nModel Equation:\\n\\nLinear regression equation is a straight line (y = a + bx).\\nPolynomial regression equation involves powers of the independent variable (e.g., y = a + bx + cx^2 for a quadratic model).\\nBest Fit:\\n\\nLinear regression finds the line that minimizes the sum of squared errors.\\nPolynomial regression finds the curve that best fits the data, also minimizing errors.\\nWhen to Choose Polynomial Regression:\\n\\nVisual inspection of data suggests a non-linear pattern.\\nLinear regression fails to capture the relationship adequately.\\nUnderstanding the underlying process suggests a potential non-linear relationship.\\nCaution:\\n\\nOverfitting: Higher-degree polynomials can overfit the data, poorly predicting new data points.\\nInterpretation: Interpreting polynomial coefficients can be more challenging than linear coefficients.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Polynomial Regression:\n",
    "\n",
    "Handles Non-Linear Relationships: It's a regression technique that models non-linear relationships between variables. Instead of fitting a straight line, it fits a curve to the data, represented by a polynomial equation.\n",
    "Flexible Patterns: It can capture various patterns, including U-shapes, inverted U-shapes, and multiple peaks and valleys, making it more adaptable than linear regression for complex relationships.\n",
    "Degree of Polynomial: The model's flexibility is determined by the degree of the polynomial used (e.g., quadratic, cubic, quartic). Higher degrees allow for more complex curves but also increase the risk of overfitting.\n",
    "Key Differences from Linear Regression:\n",
    "\n",
    "Relationship Shape:\n",
    "\n",
    "Linear regression assumes a straight-line relationship between variables.\n",
    "Polynomial regression allows for non-linear, curved relationships.\n",
    "Model Equation:\n",
    "\n",
    "Linear regression equation is a straight line (y = a + bx).\n",
    "Polynomial regression equation involves powers of the independent variable (e.g., y = a + bx + cx^2 for a quadratic model).\n",
    "Best Fit:\n",
    "\n",
    "Linear regression finds the line that minimizes the sum of squared errors.\n",
    "Polynomial regression finds the curve that best fits the data, also minimizing errors.\n",
    "When to Choose Polynomial Regression:\n",
    "\n",
    "Visual inspection of data suggests a non-linear pattern.\n",
    "Linear regression fails to capture the relationship adequately.\n",
    "Understanding the underlying process suggests a potential non-linear relationship.\n",
    "Caution:\n",
    "\n",
    "Overfitting: Higher-degree polynomials can overfit the data, poorly predicting new data points.\n",
    "Interpretation: Interpreting polynomial coefficients can be more challenging than linear coefficients.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc7b394-57de-4179-817d-3cc7a608bb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q8. What are the advantages and disadvantages of polynomial regression compared to linear\\nregression? In what situations would you prefer to use polynomial regression?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52314e51-5ceb-4606-875b-37afaa8c70f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdvantages of Polynomial Regression:\\n\\nCaptures Non-linear Patterns:\\n\\nPolynomial regression is capable of capturing more complex and non-linear relationships between the independent and dependent variables.\\nIncreased Flexibility:\\n\\nIt offers greater flexibility in modeling the data by allowing curves, bends, and other non-linear shapes in the relationship.\\nBetter Fit to Data:\\n\\nIn situations where the true relationship is non-linear, polynomial regression can provide a better fit to the data compared to linear regression.\\nHandles Curved Trends:\\n\\nUseful when dealing with phenomena where the relationship displays curves or other non-linear patterns.\\nDisadvantages of Polynomial Regression:\\n\\nOverfitting Risk:\\n\\nPolynomial regression, especially with higher-degree polynomials, is more susceptible to overfitting. The model might fit the training data too closely, capturing noise and leading to poor generalization on new data.\\nComplexity and Interpretability:\\n\\nAs the degree of the polynomial increases, the model becomes more complex. This complexity can make it challenging to interpret coefficients and understand the true nature of the relationship.\\nSensitive to Outliers:\\n\\nPolynomial regression can be sensitive to outliers, and a single outlier can have a significant impact on the fitted curve.\\nChoice of Degree:\\n\\nSelecting the appropriate degree for the polynomial is crucial. Too low a degree may result in underfitting, while too high a degree may lead to overfitting.\\nWhen to Prefer Polynomial Regression:\\n\\nNon-linear Relationships:\\n\\nWhen the relationship between the independent and dependent variables is not adequately represented by a straight line.\\nComplex Patterns:\\n\\nIn situations where the data exhibits curves, bends, or other non-linear patterns that linear regression cannot capture.\\nFlexibility Needed:\\n\\nWhen flexibility in modeling is required, and the trade-off with interpretability is acceptable.\\nAppropriate Degree:\\n\\nWhen the degree of the polynomial is carefully chosen based on the characteristics of the data. A higher degree should be used judiciously to avoid overfitting.\\nSituational Suitability:\\n\\nIn scenarios where the advantages of capturing non-linear patterns outweigh the disadvantages of increased complexity and potential overfitting.\\nWhen to Prefer Linear Regression:\\n\\nSimple Relationships:\\n\\nWhen the relationship between the independent and dependent variables is approximately linear.\\nInterpretability:\\n\\nIn situations where the interpretability of coefficients is crucial, and a simpler model is preferred.\\nLower Risk of Overfitting:\\n\\nWhen the risk of overfitting is a concern, and a more parsimonious model is desired.\\nStability:\\n\\nIn cases where the dataset is relatively small, and a more stable model is needed.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Advantages of Polynomial Regression:\n",
    "\n",
    "Captures Non-linear Patterns:\n",
    "\n",
    "Polynomial regression is capable of capturing more complex and non-linear relationships between the independent and dependent variables.\n",
    "Increased Flexibility:\n",
    "\n",
    "It offers greater flexibility in modeling the data by allowing curves, bends, and other non-linear shapes in the relationship.\n",
    "Better Fit to Data:\n",
    "\n",
    "In situations where the true relationship is non-linear, polynomial regression can provide a better fit to the data compared to linear regression.\n",
    "Handles Curved Trends:\n",
    "\n",
    "Useful when dealing with phenomena where the relationship displays curves or other non-linear patterns.\n",
    "Disadvantages of Polynomial Regression:\n",
    "\n",
    "Overfitting Risk:\n",
    "\n",
    "Polynomial regression, especially with higher-degree polynomials, is more susceptible to overfitting. The model might fit the training data too closely, capturing noise and leading to poor generalization on new data.\n",
    "Complexity and Interpretability:\n",
    "\n",
    "As the degree of the polynomial increases, the model becomes more complex. This complexity can make it challenging to interpret coefficients and understand the true nature of the relationship.\n",
    "Sensitive to Outliers:\n",
    "\n",
    "Polynomial regression can be sensitive to outliers, and a single outlier can have a significant impact on the fitted curve.\n",
    "Choice of Degree:\n",
    "\n",
    "Selecting the appropriate degree for the polynomial is crucial. Too low a degree may result in underfitting, while too high a degree may lead to overfitting.\n",
    "When to Prefer Polynomial Regression:\n",
    "\n",
    "Non-linear Relationships:\n",
    "\n",
    "When the relationship between the independent and dependent variables is not adequately represented by a straight line.\n",
    "Complex Patterns:\n",
    "\n",
    "In situations where the data exhibits curves, bends, or other non-linear patterns that linear regression cannot capture.\n",
    "Flexibility Needed:\n",
    "\n",
    "When flexibility in modeling is required, and the trade-off with interpretability is acceptable.\n",
    "Appropriate Degree:\n",
    "\n",
    "When the degree of the polynomial is carefully chosen based on the characteristics of the data. A higher degree should be used judiciously to avoid overfitting.\n",
    "Situational Suitability:\n",
    "\n",
    "In scenarios where the advantages of capturing non-linear patterns outweigh the disadvantages of increased complexity and potential overfitting.\n",
    "When to Prefer Linear Regression:\n",
    "\n",
    "Simple Relationships:\n",
    "\n",
    "When the relationship between the independent and dependent variables is approximately linear.\n",
    "Interpretability:\n",
    "\n",
    "In situations where the interpretability of coefficients is crucial, and a simpler model is preferred.\n",
    "Lower Risk of Overfitting:\n",
    "\n",
    "When the risk of overfitting is a concern, and a more parsimonious model is desired.\n",
    "Stability:\n",
    "\n",
    "In cases where the dataset is relatively small, and a more stable model is needed.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225d045-e01b-4b80-8f9d-c11d0077c8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
